{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from Get_Metadata import Get_Metadata, plot_confusion_matrix\n",
    "\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import classification_report\n",
    "from keras import callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.layers import Add, Input, Reshape,Concatenate, Conv1D, MaxPooling1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Read input\n",
    "def read_input():\n",
    "  input_file = \"https://raw.githubusercontent.com/wangcunxiang/SemEval2020-Task4-Commonsense-Validation-and-Explanation/master/Training%20%20Data/subtaskB_data_all.csv\"\n",
    "  ans_file = \"https://raw.githubusercontent.com/wangcunxiang/SemEval2020-Task4-Commonsense-Validation-and-Explanation/master/Training%20%20Data/subtaskB_answers_all.csv\"\n",
    "  df_ans = pd.read_csv(ans_file, header=None, names=[\"id\", \"ans\"])\n",
    "  df_input = pd.read_csv(input_file)\n",
    "  return df_input, df_ans\n",
    "\n",
    "df_input, df_ans = read_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemLine(sentence):\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    translator = ''.join(ch for ch in sentence if ch not in punctuation)\n",
    "   # translator=sentence.translate(string.maketrans('','', string.punctuation))\n",
    "    translator = translator.lower()\n",
    "    tokeniz = WordPunctTokenizer()\n",
    "    tokens = tokeniz.tokenize(translator)\n",
    "    #tokens = word_tokenize(translator)\n",
    "    final = [stemmer.stem(tagged_word) for tagged_word in tokens]\n",
    "    return \" \".join(final)\n",
    "\n",
    "\n",
    "df_input['FalseSentStemmed'] = df_input['FalseSent'].apply(lambda row: stemLine(row))\n",
    "df_input['OptionAStemmed'] = df_input['OptionA'].apply(lambda row: stemLine(row))\n",
    "df_input['OptionBStemmed'] = df_input['OptionA'].apply(lambda row: stemLine(row))\n",
    "df_input['OptionCStemmed'] = df_input['OptionA'].apply(lambda row: stemLine(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>FalseSent</th>\n",
       "      <th>OptionA</th>\n",
       "      <th>OptionB</th>\n",
       "      <th>OptionC</th>\n",
       "      <th>FalseSentStemmed</th>\n",
       "      <th>OptionAStemmed</th>\n",
       "      <th>OptionBStemmed</th>\n",
       "      <th>OptionCStemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>He poured orange juice on his cereal.</td>\n",
       "      <td>Orange juice is usually bright orange.</td>\n",
       "      <td>Orange juice doesn't taste good on cereal.</td>\n",
       "      <td>Orange juice is sticky if you spill it on the ...</td>\n",
       "      <td>he pour orang juic on hi cereal</td>\n",
       "      <td>orang juic is usual bright orang</td>\n",
       "      <td>orang juic is usual bright orang</td>\n",
       "      <td>orang juic is usual bright orang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>He drinks apple.</td>\n",
       "      <td>Apple juice are very tasty and milk too</td>\n",
       "      <td>Apple can not be drunk</td>\n",
       "      <td>Apple cannot eat a human</td>\n",
       "      <td>he drink appl</td>\n",
       "      <td>appl juic are veri tasti and milk too</td>\n",
       "      <td>appl juic are veri tasti and milk too</td>\n",
       "      <td>appl juic are veri tasti and milk too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jeff ran 100,000 miles today</td>\n",
       "      <td>100,000 miles is way to long for one person to...</td>\n",
       "      <td>Jeff is a four letter name and 100,000 has six...</td>\n",
       "      <td>100,000 miles is longer than 100,000 km.</td>\n",
       "      <td>jeff ran 100000 mile today</td>\n",
       "      <td>100000 mile is way to long for one person to b...</td>\n",
       "      <td>100000 mile is way to long for one person to b...</td>\n",
       "      <td>100000 mile is way to long for one person to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I sting a mosquito</td>\n",
       "      <td>A human is a mammal</td>\n",
       "      <td>A human is omnivorous</td>\n",
       "      <td>A human has not stings</td>\n",
       "      <td>i sting a mosquito</td>\n",
       "      <td>a human is a mammal</td>\n",
       "      <td>a human is a mammal</td>\n",
       "      <td>a human is a mammal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A giraffe is a person.</td>\n",
       "      <td>Giraffes can drink water from a lake.</td>\n",
       "      <td>A giraffe is not a human being.</td>\n",
       "      <td>.Giraffes usually eat leaves.</td>\n",
       "      <td>a giraff is a person</td>\n",
       "      <td>giraff can drink water from a lake</td>\n",
       "      <td>giraff can drink water from a lake</td>\n",
       "      <td>giraff can drink water from a lake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                              FalseSent  \\\n",
       "0   0  He poured orange juice on his cereal.   \n",
       "1   1                       He drinks apple.   \n",
       "2   2           Jeff ran 100,000 miles today   \n",
       "3   3                     I sting a mosquito   \n",
       "4   4                 A giraffe is a person.   \n",
       "\n",
       "                                             OptionA  \\\n",
       "0             Orange juice is usually bright orange.   \n",
       "1            Apple juice are very tasty and milk too   \n",
       "2  100,000 miles is way to long for one person to...   \n",
       "3                                A human is a mammal   \n",
       "4              Giraffes can drink water from a lake.   \n",
       "\n",
       "                                             OptionB  \\\n",
       "0         Orange juice doesn't taste good on cereal.   \n",
       "1                             Apple can not be drunk   \n",
       "2  Jeff is a four letter name and 100,000 has six...   \n",
       "3                              A human is omnivorous   \n",
       "4                    A giraffe is not a human being.   \n",
       "\n",
       "                                             OptionC  \\\n",
       "0  Orange juice is sticky if you spill it on the ...   \n",
       "1                           Apple cannot eat a human   \n",
       "2           100,000 miles is longer than 100,000 km.   \n",
       "3                             A human has not stings   \n",
       "4                      .Giraffes usually eat leaves.   \n",
       "\n",
       "                  FalseSentStemmed  \\\n",
       "0  he pour orang juic on hi cereal   \n",
       "1                    he drink appl   \n",
       "2       jeff ran 100000 mile today   \n",
       "3               i sting a mosquito   \n",
       "4             a giraff is a person   \n",
       "\n",
       "                                      OptionAStemmed  \\\n",
       "0                   orang juic is usual bright orang   \n",
       "1              appl juic are veri tasti and milk too   \n",
       "2  100000 mile is way to long for one person to b...   \n",
       "3                                a human is a mammal   \n",
       "4                 giraff can drink water from a lake   \n",
       "\n",
       "                                      OptionBStemmed  \\\n",
       "0                   orang juic is usual bright orang   \n",
       "1              appl juic are veri tasti and milk too   \n",
       "2  100000 mile is way to long for one person to b...   \n",
       "3                                a human is a mammal   \n",
       "4                 giraff can drink water from a lake   \n",
       "\n",
       "                                      OptionCStemmed  \n",
       "0                   orang juic is usual bright orang  \n",
       "1              appl juic are veri tasti and milk too  \n",
       "2  100000 mile is way to long for one person to b...  \n",
       "3                                a human is a mammal  \n",
       "4                 giraff can drink water from a lake  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id label  encoded\n",
       "0   0     B        1\n",
       "1   1     B        1\n",
       "2   2     A        0\n",
       "3   3     C        2\n",
       "4   4     B        1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df_ans.columns = ['id', 'label']\n",
    "df_ans['encoded'] = le.fit_transform(df_ans['label'])\n",
    "df_ans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>FalseSentStemmed</th>\n",
       "      <th>OptionAStemmed</th>\n",
       "      <th>OptionBStemmed</th>\n",
       "      <th>OptionCStemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>he pour orang juic on hi cereal</td>\n",
       "      <td>orang juic is usual bright orang</td>\n",
       "      <td>orang juic is usual bright orang</td>\n",
       "      <td>orang juic is usual bright orang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>he drink appl</td>\n",
       "      <td>appl juic are veri tasti and milk too</td>\n",
       "      <td>appl juic are veri tasti and milk too</td>\n",
       "      <td>appl juic are veri tasti and milk too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>jeff ran 100000 mile today</td>\n",
       "      <td>100000 mile is way to long for one person to b...</td>\n",
       "      <td>100000 mile is way to long for one person to b...</td>\n",
       "      <td>100000 mile is way to long for one person to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>i sting a mosquito</td>\n",
       "      <td>a human is a mammal</td>\n",
       "      <td>a human is a mammal</td>\n",
       "      <td>a human is a mammal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a giraff is a person</td>\n",
       "      <td>giraff can drink water from a lake</td>\n",
       "      <td>giraff can drink water from a lake</td>\n",
       "      <td>giraff can drink water from a lake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                 FalseSentStemmed  \\\n",
       "0   0  he pour orang juic on hi cereal   \n",
       "1   1                    he drink appl   \n",
       "2   2       jeff ran 100000 mile today   \n",
       "3   3               i sting a mosquito   \n",
       "4   4             a giraff is a person   \n",
       "\n",
       "                                      OptionAStemmed  \\\n",
       "0                   orang juic is usual bright orang   \n",
       "1              appl juic are veri tasti and milk too   \n",
       "2  100000 mile is way to long for one person to b...   \n",
       "3                                a human is a mammal   \n",
       "4                 giraff can drink water from a lake   \n",
       "\n",
       "                                      OptionBStemmed  \\\n",
       "0                   orang juic is usual bright orang   \n",
       "1              appl juic are veri tasti and milk too   \n",
       "2  100000 mile is way to long for one person to b...   \n",
       "3                                a human is a mammal   \n",
       "4                 giraff can drink water from a lake   \n",
       "\n",
       "                                      OptionCStemmed  \n",
       "0                   orang juic is usual bright orang  \n",
       "1              appl juic are veri tasti and milk too  \n",
       "2  100000 mile is way to long for one person to b...  \n",
       "3                                a human is a mammal  \n",
       "4                 giraff can drink water from a lake  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data = df_input.drop(['FalseSent','OptionA', 'OptionB', 'OptionC'],axis=1)   #.iloc[:,:-1]\n",
    "#meta_data = Get_Metadata(meta_data)\n",
    "meta_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsorted_words_FalseSent = get_sorted_words(meta_data['FalseSentStemmed'])\\nsorted_words_OptA = get_sorted_words(meta_data['OptionAStemmed'])\\nsorted_words_OptB = get_sorted_words(meta_data['OptionBStemmed'])\\nsorted_words_OptC = get_sorted_words(meta_data['OptionCStemmed'])\\n\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "all_text2_FalseSent = ' '.join(meta_data['FalseSentStemmed'])\n",
    "# create a list of words\n",
    "words = all_text2_FalseSent.split()\n",
    "# Count all the words using Counter Method\n",
    "count_words = Counter(words)\n",
    "total_words = len(words)\n",
    "sorted_words_FalseSent = count_words.most_common(total_words)\n",
    "\n",
    "all_text2_OptA = ' '.join(meta_data['OptionAStemmed'])\n",
    "# create a list of words\n",
    "words = all_text2_OptA.split()\n",
    "# Count all the words using Counter Method\n",
    "count_words = Counter(words)\n",
    "total_words = len(words)\n",
    "sorted_words_OptA = count_words.most_common(total_words)\n",
    "\n",
    "all_text2_OptB = ' '.join(meta_data['OptionBStemmed'])\n",
    "# create a list of words\n",
    "words = all_text2_OptB.split()\n",
    "# Count all the words using Counter Method\n",
    "count_words = Counter(words)\n",
    "total_words = len(words)\n",
    "sorted_words_OptB = count_words.most_common(total_words)\n",
    "\n",
    "all_text2_OptC = ' '.join(meta_data['OptionCStemmed'])\n",
    "# create a list of words\n",
    "words = all_text2_OptC.split()\n",
    "# Count all the words using Counter Method\n",
    "count_words = Counter(words)\n",
    "total_words = len(words)\n",
    "sorted_words_OptC = count_words.most_common(total_words)\n",
    "\n",
    "'''\n",
    "sorted_words_FalseSent = get_sorted_words(meta_data['FalseSentStemmed'])\n",
    "sorted_words_OptA = get_sorted_words(meta_data['OptionAStemmed'])\n",
    "sorted_words_OptB = get_sorted_words(meta_data['OptionBStemmed'])\n",
    "sorted_words_OptC = get_sorted_words(meta_data['OptionCStemmed'])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5203\n",
      "5203\n",
      "5203\n"
     ]
    }
   ],
   "source": [
    "vocab_to_int_FalseSent = {w:i+1 for i, (w,c) in enumerate(sorted_words_FalseSent)}\n",
    "vocab_to_int_OptA = {w:i+1 for i, (w,c) in enumerate(sorted_words_OptA)}\n",
    "vocab_to_int_OptB = {w:i+1 for i, (w,c) in enumerate(sorted_words_OptB)}\n",
    "vocab_to_int_OptC = {w:i+1 for i, (w,c) in enumerate(sorted_words_OptC)}\n",
    "print(len(vocab_to_int_OptA))\n",
    "print(len(vocab_to_int_OptB))\n",
    "print(len(vocab_to_int_OptC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "FalseSent_int = []\n",
    "for d in meta_data['FalseSentStemmed']:\n",
    "    r = [vocab_to_int_FalseSent[w] for w in d.split()]\n",
    "    FalseSent_int.append(r)\n",
    "\n",
    "OptA_int = []\n",
    "for d in meta_data['OptionAStemmed']:\n",
    "    r = [vocab_to_int_OptA[w] for w in d.split()]\n",
    "    OptA_int.append(r)\n",
    "    \n",
    "OptB_int = []\n",
    "for d in meta_data['OptionBStemmed']:\n",
    "    r = [vocab_to_int_OptB[w] for w in d.split()]\n",
    "    OptB_int.append(r)\n",
    "    \n",
    "OptC_int = []\n",
    "for d in meta_data['OptionCStemmed']:\n",
    "    r = [vocab_to_int_OptC[w] for w in d.split()]\n",
    "    OptC_int.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_len_FalseSent = [len(x) for x in FalseSent_int]\n",
    "desc_len_OptA = [len(x) for x in OptA_int]\n",
    "desc_len_OptB = [len(x) for x in OptB_int]\n",
    "desc_len_OptC = [len(x) for x in OptC_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    6  378  801  634    8\n",
      "   13 1488]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "pad_len_FalseSent = pd.Series(desc_len_FalseSent).max()\n",
    "pad_len_OptA = pd.Series(desc_len_OptA).max()\n",
    "pad_len_OptB = pd.Series(desc_len_OptB).max()\n",
    "pad_len_OptC = pd.Series(desc_len_OptC).max()\n",
    "pad_len = max([pad_len_FalseSent, pad_len_OptA, pad_len_OptB, pad_len_OptC])\n",
    "#add padding to input\n",
    "padded_FalseSent = pad_sequences(FalseSent_int, pad_len)\n",
    "padded_OptA = pad_sequences(OptA_int, pad_len)\n",
    "padded_OptB = pad_sequences(OptB_int, pad_len)\n",
    "padded_OptC = pad_sequences(OptC_int, pad_len)\n",
    "print(padded_FalseSent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 30) (2000, 30)\n",
      "[[   0    0    0 ...    8   13 1488]\n",
      " [   0    0    0 ...    6   54  132]\n",
      " [   0    0    0 ... 3103 1065  276]\n",
      " ...\n",
      " [   0    0    0 ...  191    3  701]\n",
      " [   0    0    0 ...   10  480   54]\n",
      " [   0    0    0 ...  292   33 1270]]\n",
      "[[   0    0    0 ...    8   13 1488]\n",
      " [   0    0    0 ...    6   54  132]\n",
      " [   0    0    0 ... 3103 1065  276]\n",
      " ...\n",
      " [   0    0    0 ...   39    3   24]\n",
      " [   0    0    0 ...    3    1  163]\n",
      " [   0    0    0 ...  193   20  142]]\n",
      "[[   0    0    0 ...  411    9 4650]\n",
      " [   0    0    0 ...    4  694  368]\n",
      " [   0    0    0 ...   12  149  190]\n",
      " ...\n",
      " [   0    0    0 ...   13  183 1007]\n",
      " [   0    0    0 ...    8    1  291]\n",
      " [   0    0    0 ...    8   15  501]]\n"
     ]
    }
   ],
   "source": [
    "#FalseSent padding\n",
    "\n",
    "data_pad_FalseSent = padded_FalseSent\n",
    "train_rows = int(len(data_pad_FalseSent)*0.8)\n",
    "test_rows = len(data_pad_FalseSent)-train_rows\n",
    "#y_train=data['bot'][:train_rows]\n",
    "X_train_0=data_pad_FalseSent[:train_rows]\n",
    "\n",
    "X_test_0= data_pad_FalseSent[train_rows:]\n",
    "\n",
    "print(X_train_0.shape, X_test_0.shape)\n",
    "\n",
    "print(data_pad_FalseSent[:train_rows])\n",
    "print(data_pad_FalseSent[:test_rows])\n",
    "print(data_pad_FalseSent[train_rows:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 30) (2000, 30)\n"
     ]
    }
   ],
   "source": [
    "#OptionA padding\n",
    "\n",
    "data_pad_OptA = padded_OptA\n",
    "train_rows = int(len(data_pad_OptA)*0.8)\n",
    "test_rows = len(data_pad_OptA)-train_rows\n",
    "#y_train=data['bot'][:train_rows]\n",
    "X_train_1=data_pad_OptA[:train_rows]\n",
    "\n",
    "X_test_1= data_pad_OptA[train_rows:]\n",
    "\n",
    "print(X_train_1.shape, X_test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 30) (2000, 30)\n"
     ]
    }
   ],
   "source": [
    "#OptionB padding\n",
    "\n",
    "data_pad_OptB = padded_OptB\n",
    "train_rows = int(len(data_pad_OptB)*0.8)\n",
    "test_rows = len(data_pad_OptB)-train_rows\n",
    "#y_train=data['bot'][:train_rows]\n",
    "X_train_2=data_pad_OptB[:train_rows]\n",
    "\n",
    "X_test_2= data_pad_OptB[train_rows:]\n",
    "\n",
    "print(X_train_2.shape, X_test_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 30) (2000, 30)\n"
     ]
    }
   ],
   "source": [
    "#OptionC padding\n",
    "\n",
    "data_pad_OptC = padded_OptC\n",
    "train_rows = int(len(data_pad_OptC)*0.8)\n",
    "test_rows = len(data_pad_OptC)-train_rows\n",
    "#y_train=data['bot'][:train_rows]\n",
    "X_train_3=data_pad_OptC[:train_rows]\n",
    "\n",
    "X_test_3= data_pad_OptC[train_rows:]\n",
    "\n",
    "print(X_train_3.shape, X_test_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "(10000,) (8000, 3)\n",
      "true\n"
     ]
    }
   ],
   "source": [
    "#one-hot encoding truth values \n",
    "from keras.utils import to_categorical\n",
    "\n",
    "encoded_labels = df_ans['encoded']\n",
    "print(len(df_ans))\n",
    "\n",
    "y = encoded_labels\n",
    "#y_svm_train = y[:train_rows]\n",
    "#y_svm_test = y[:test_rows]\n",
    "y = to_categorical(y)\n",
    "y_train = y[:train_rows]\n",
    "y_train = y_train\n",
    "y_test = y[train_rows:]\n",
    "print(np.array(encoded_labels).shape,y_train.shape)\n",
    "# invert encoding\n",
    "inverted = np.argmax(y_train[0])\n",
    "if(inverted>0): print(\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classification using LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 80)\n",
      "Train on 7200 samples, validate on 800 samples\n",
      "Epoch 1/30\n",
      "7200/7200 [==============================] - 6s 866us/step - loss: 1.0408 - accuracy: 0.4101 - val_loss: 0.9428 - val_accuracy: 0.4963\n",
      "Epoch 2/30\n",
      "7200/7200 [==============================] - 6s 778us/step - loss: 0.8620 - accuracy: 0.5393 - val_loss: 0.9351 - val_accuracy: 0.5038\n",
      "Epoch 3/30\n",
      "7200/7200 [==============================] - 6s 844us/step - loss: 0.7349 - accuracy: 0.6004 - val_loss: 0.9989 - val_accuracy: 0.4762\n",
      "Epoch 4/30\n",
      "7200/7200 [==============================] - 6s 828us/step - loss: 0.6173 - accuracy: 0.6582 - val_loss: 1.2569 - val_accuracy: 0.4625\n",
      "Epoch 5/30\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5238 - accuracy: 0.7286 - val_loss: 1.4928 - val_accuracy: 0.4588\n",
      "Epoch 6/30\n",
      "7200/7200 [==============================] - 7s 1ms/step - loss: 0.4172 - accuracy: 0.8018 - val_loss: 2.0440 - val_accuracy: 0.4712\n",
      "Epoch 7/30\n",
      "7200/7200 [==============================] - 7s 964us/step - loss: 0.3122 - accuracy: 0.8646 - val_loss: 2.4194 - val_accuracy: 0.4762\n",
      "Epoch 8/30\n",
      "7200/7200 [==============================] - 6s 829us/step - loss: 0.2150 - accuracy: 0.9086 - val_loss: 2.6352 - val_accuracy: 0.4725\n",
      "Epoch 9/30\n",
      "7200/7200 [==============================] - 6s 788us/step - loss: 0.1462 - accuracy: 0.9435 - val_loss: 3.3051 - val_accuracy: 0.4750\n",
      "Epoch 10/30\n",
      "7200/7200 [==============================] - 7s 940us/step - loss: 0.1038 - accuracy: 0.9585 - val_loss: 3.6041 - val_accuracy: 0.4625\n",
      "Epoch 11/30\n",
      "7200/7200 [==============================] - 7s 965us/step - loss: 0.0752 - accuracy: 0.9744 - val_loss: 3.8176 - val_accuracy: 0.4775\n",
      "Epoch 12/30\n",
      "7200/7200 [==============================] - 6s 833us/step - loss: 0.0563 - accuracy: 0.9817 - val_loss: 4.4029 - val_accuracy: 0.4650\n",
      "Epoch 13/30\n",
      "7200/7200 [==============================] - 6s 866us/step - loss: 0.0362 - accuracy: 0.9885 - val_loss: 5.2647 - val_accuracy: 0.4625\n",
      "Epoch 14/30\n",
      "7200/7200 [==============================] - 6s 875us/step - loss: 0.0263 - accuracy: 0.9911 - val_loss: 5.3937 - val_accuracy: 0.4675\n",
      "Epoch 15/30\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 5.6639 - val_accuracy: 0.4575\n",
      "Epoch 16/30\n",
      "7200/7200 [==============================] - 7s 970us/step - loss: 0.0250 - accuracy: 0.9908 - val_loss: 5.8247 - val_accuracy: 0.4600\n",
      "Epoch 17/30\n",
      "7200/7200 [==============================] - 7s 947us/step - loss: 0.0330 - accuracy: 0.9892 - val_loss: 5.8805 - val_accuracy: 0.4663\n",
      "Epoch 18/30\n",
      "7200/7200 [==============================] - 7s 958us/step - loss: 0.0269 - accuracy: 0.9903 - val_loss: 5.9943 - val_accuracy: 0.4762\n",
      "Epoch 19/30\n",
      "7200/7200 [==============================] - 7s 919us/step - loss: 0.0297 - accuracy: 0.9906 - val_loss: 5.5700 - val_accuracy: 0.4487\n",
      "Epoch 20/30\n",
      "7200/7200 [==============================] - 7s 958us/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 6.8574 - val_accuracy: 0.4625\n",
      "Epoch 21/30\n",
      "7200/7200 [==============================] - 7s 968us/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 7.0672 - val_accuracy: 0.4575\n",
      "Epoch 22/30\n",
      "7200/7200 [==============================] - 7s 937us/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 7.7911 - val_accuracy: 0.4675\n",
      "Epoch 23/30\n",
      "7200/7200 [==============================] - 7s 962us/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 6.8164 - val_accuracy: 0.4412\n",
      "Epoch 24/30\n",
      "7200/7200 [==============================] - 7s 978us/step - loss: 0.0155 - accuracy: 0.9940 - val_loss: 7.0247 - val_accuracy: 0.4675\n",
      "Epoch 25/30\n",
      "7200/7200 [==============================] - 7s 943us/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 6.4203 - val_accuracy: 0.4700\n",
      "Epoch 26/30\n",
      "7200/7200 [==============================] - 7s 948us/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 5.6593 - val_accuracy: 0.4600\n",
      "Epoch 27/30\n",
      "7200/7200 [==============================] - 7s 967us/step - loss: 0.0216 - accuracy: 0.9925 - val_loss: 6.2650 - val_accuracy: 0.4462\n",
      "Epoch 28/30\n",
      "7200/7200 [==============================] - 7s 964us/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 6.0996 - val_accuracy: 0.4750\n",
      "Epoch 29/30\n",
      "7200/7200 [==============================] - 7s 947us/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 6.8564 - val_accuracy: 0.4650\n",
      "Epoch 30/30\n",
      "7200/7200 [==============================] - 7s 946us/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 7.0252 - val_accuracy: 0.4512\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "\n",
    "def task4A_LSTM_model(X_train,y_train):\n",
    "    \n",
    "    X_train_0,X_train_1,X_train_2,X_train_3 = X_train\n",
    "    embedding_vecor_length = X_train_0.shape[1]\n",
    "   # model0 = Sequential()\n",
    "    batch_size=45\n",
    "    #model0\n",
    "    input0 = Input(shape=(X_train_0.shape[1],))\n",
    "    x0 = Embedding(len(vocab_to_int_FalseSent)+1, embedding_vecor_length, input_length=X_train_0.shape[1])(input0)\n",
    "    x0 = LSTM(20)(x0) #,batch_input_shape=(batch_size,19,1957)))\n",
    "    \n",
    "    #model1\n",
    "   # model1 = Sequential()\n",
    "    input1 = Input(shape=(X_train_1.shape[1],))\n",
    "    x1 = Embedding(len(vocab_to_int_OptA)+1, embedding_vecor_length, input_length=X_train_1.shape[1])(input1)\n",
    "    x1 = LSTM(20)(x1) #,batch_input_shape=(batch_size,19,1957)))\n",
    "    \n",
    "    #model2\n",
    "    # model1 = Sequential()\n",
    "    input2 = Input(shape=(X_train_2.shape[1],))\n",
    "    x2 = Embedding(len(vocab_to_int_OptB)+1, embedding_vecor_length, input_length=X_train_2.shape[1])(input2)\n",
    "    x2 = LSTM(20)(x2) #,batch_input_shape=(batch_size,19,1957)))\n",
    "    \n",
    "    #model3\n",
    "    # model1 = Sequential()\n",
    "    input3 = Input(shape=(X_train_3.shape[1],))\n",
    "    x3 = Embedding(len(vocab_to_int_OptC)+1, embedding_vecor_length, input_length=X_train_3.shape[1])(input3)\n",
    "    x3 = LSTM(20)(x3) #,batch_input_shape=(batch_size,19,1957)))\n",
    "    \n",
    "    model = Sequential()\n",
    "    x = Concatenate()([x0,x1,x2,x3])\n",
    "    print(x.shape)\n",
    "    x = Reshape((4,20),)(x)\n",
    "    x = LSTM(20, activation = 'relu')(x)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    x = Dense(3, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=[input0, input1, input2, input3], outputs=x)\n",
    "    #opt = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    es = callbacks.EarlyStopping(monitor='val_loss', mode='min', min_delta=0,patience=7)\n",
    "    mc = callbacks.ModelCheckpoint('task4A_LSTM_model.h5')\n",
    "    \n",
    "    model.fit([X_train_0,X_train_1,X_train_2,X_train_3], y_train, epochs=30, shuffle=True, callbacks=[mc],validation_split=0.1)\n",
    "    return model\n",
    "\n",
    "#print(model.summary()\n",
    "model= task4A_LSTM_model([X_train_0, X_train_1, X_train_2, X_train_3],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 30, 30)       152940      input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 30, 30)       156120      input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 30, 30)       156120      input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 30, 30)       156120      input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_13 (LSTM)                  (None, 20)           4080        embedding_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                  (None, 20)           4080        embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                  (None, 20)           4080        embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_16 (LSTM)                  (None, 20)           4080        embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 80)           0           lstm_13[0][0]                    \n",
      "                                                                 lstm_14[0][0]                    \n",
      "                                                                 lstm_15[0][0]                    \n",
      "                                                                 lstm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 4, 20)        0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_17 (LSTM)                  (None, 20)           3280        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10)           210         lstm_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 3)            33          dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 641,143\n",
      "Trainable params: 641,143\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 171us/step\n",
      "[7.864671447753906, 0.41749998927116394]\n",
      "Accuracy: 41.75%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.46      0.49       646\n",
      "           1       0.37      0.43      0.39       675\n",
      "           2       0.39      0.37      0.38       679\n",
      "\n",
      "    accuracy                           0.42      2000\n",
      "   macro avg       0.43      0.42      0.42      2000\n",
      "weighted avg       0.42      0.42      0.42      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "predictions = model.predict([X_test_0, X_test_1, X_test_2,X_test_3])\n",
    "inverted = [np.argmax(i) for i in predictions]\n",
    "truth= [np.argmax(i) for i in y_test]\n",
    "#accuracy\n",
    "scores = model.evaluate([X_test_0, X_test_1, X_test_2,X_test_3], y_test, verbose=1)\n",
    "print(scores)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(classification_report(truth, inverted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_submission_form(y_test, y_pred, model_name):\n",
    "    pred_labels = open(\"pred_labels.csv\", \"w\")\n",
    "    y_test_labels = le.inverse_transform(y_test)\n",
    "    y_pred_labels = le.inverse_transform(y_pred)\n",
    "    final_result = pd.DataFrame({\"gold\": y_test_labels, \"pred\": y_pred_labels})\n",
    "    final_result.to_csv(model_name + \"gold_labels.csv\", columns = [\"gold\"], header=False)\n",
    "    final_result.to_csv(model_name + \"pred_labels.csv\", columns = [\"pred\"], header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_form(truth, inverted, \"LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result for multi-class classification using LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 41.7500%\r\n"
     ]
    }
   ],
   "source": [
    "!python3 taskB_scorer.py --gold-labels LSTMgold_labels.csv --pred-labels LSTMpred_labels.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN for multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 30, 30)       152940      input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 30, 30)       156120      input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 30, 30)       156120      input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 30, 30)       156120      input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv1D)                 (None, 28, 25)       2275        embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv1D)                 (None, 28, 25)       2275        embedding_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv1D)                 (None, 28, 25)       2275        embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv1D)                 (None, 28, 25)       2275        embedding_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 28, 100)      0           conv_0[0][0]                     \n",
      "                                                                 conv_1[0][0]                     \n",
      "                                                                 conv_2[0][0]                     \n",
      "                                                                 conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv (Conv1D)                   (None, 26, 25)       7525        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 13, 25)       0           conv[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  (None, 10)           1440        max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 3)            33          lstm_18[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 639,398\n",
      "Trainable params: 639,398\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/30\n",
      "6400/6400 [==============================] - 4s 689us/step - loss: 1.0445 - accuracy: 0.4273 - val_loss: 0.9542 - val_accuracy: 0.4938\n",
      "Epoch 2/30\n",
      "6400/6400 [==============================] - 3s 537us/step - loss: 0.8776 - accuracy: 0.5433 - val_loss: 0.9595 - val_accuracy: 0.4881\n",
      "Epoch 3/30\n",
      "6400/6400 [==============================] - 3s 510us/step - loss: 0.7591 - accuracy: 0.6008 - val_loss: 1.0346 - val_accuracy: 0.4719\n",
      "Epoch 4/30\n",
      "6400/6400 [==============================] - 3s 517us/step - loss: 0.6429 - accuracy: 0.6656 - val_loss: 1.1961 - val_accuracy: 0.4556\n",
      "Epoch 5/30\n",
      "6400/6400 [==============================] - 3s 523us/step - loss: 0.5210 - accuracy: 0.7773 - val_loss: 1.3132 - val_accuracy: 0.4544\n",
      "Epoch 6/30\n",
      "6400/6400 [==============================] - 3s 530us/step - loss: 0.3772 - accuracy: 0.8522 - val_loss: 1.6526 - val_accuracy: 0.4369\n",
      "Epoch 7/30\n",
      "6400/6400 [==============================] - 3s 511us/step - loss: 0.2628 - accuracy: 0.9064 - val_loss: 1.6370 - val_accuracy: 0.4494\n",
      "Epoch 8/30\n",
      "6400/6400 [==============================] - 3s 530us/step - loss: 0.1642 - accuracy: 0.9492 - val_loss: 1.8155 - val_accuracy: 0.4437\n",
      "Epoch 9/30\n",
      "6400/6400 [==============================] - 3s 533us/step - loss: 0.0950 - accuracy: 0.9773 - val_loss: 1.9418 - val_accuracy: 0.4556\n",
      "Epoch 10/30\n",
      "6400/6400 [==============================] - 3s 519us/step - loss: 0.0599 - accuracy: 0.9870 - val_loss: 1.9859 - val_accuracy: 0.4631\n",
      "Epoch 11/30\n",
      "6400/6400 [==============================] - 3s 535us/step - loss: 0.0439 - accuracy: 0.9919 - val_loss: 2.2125 - val_accuracy: 0.4444\n",
      "Epoch 12/30\n",
      "6400/6400 [==============================] - 3s 544us/step - loss: 0.0345 - accuracy: 0.9934 - val_loss: 2.2218 - val_accuracy: 0.4419\n",
      "Epoch 13/30\n",
      "6400/6400 [==============================] - 3s 505us/step - loss: 0.0283 - accuracy: 0.9953 - val_loss: 2.2466 - val_accuracy: 0.4469\n",
      "Epoch 14/30\n",
      "6400/6400 [==============================] - 3s 534us/step - loss: 0.0225 - accuracy: 0.9950 - val_loss: 2.3233 - val_accuracy: 0.4475\n",
      "Epoch 15/30\n",
      "6400/6400 [==============================] - 3s 535us/step - loss: 0.0202 - accuracy: 0.9962 - val_loss: 2.3888 - val_accuracy: 0.4369\n",
      "Epoch 16/30\n",
      "6400/6400 [==============================] - 3s 543us/step - loss: 0.0140 - accuracy: 0.9986 - val_loss: 2.4477 - val_accuracy: 0.4281\n",
      "Epoch 17/30\n",
      "6400/6400 [==============================] - 3s 532us/step - loss: 0.0087 - accuracy: 0.9994 - val_loss: 2.5141 - val_accuracy: 0.4369\n",
      "Epoch 18/30\n",
      "6400/6400 [==============================] - 3s 534us/step - loss: 0.0068 - accuracy: 0.9995 - val_loss: 2.5491 - val_accuracy: 0.4338\n",
      "Epoch 19/30\n",
      "6400/6400 [==============================] - 3s 518us/step - loss: 0.0055 - accuracy: 0.9997 - val_loss: 2.6085 - val_accuracy: 0.4394\n",
      "Epoch 20/30\n",
      "6400/6400 [==============================] - 3s 522us/step - loss: 0.0042 - accuracy: 0.9998 - val_loss: 2.6566 - val_accuracy: 0.4369\n",
      "Epoch 21/30\n",
      "6400/6400 [==============================] - 3s 524us/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 2.7109 - val_accuracy: 0.4325\n",
      "Epoch 22/30\n",
      "6400/6400 [==============================] - 3s 523us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.7632 - val_accuracy: 0.4363\n",
      "Epoch 23/30\n",
      "6400/6400 [==============================] - 3s 518us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.8041 - val_accuracy: 0.4369\n",
      "Epoch 24/30\n",
      "6400/6400 [==============================] - 3s 543us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.8459 - val_accuracy: 0.4381\n",
      "Epoch 25/30\n",
      "6400/6400 [==============================] - 3s 531us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.8875 - val_accuracy: 0.4381\n",
      "Epoch 26/30\n",
      "6400/6400 [==============================] - 3s 539us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.9289 - val_accuracy: 0.4381\n",
      "Epoch 27/30\n",
      "6400/6400 [==============================] - 4s 554us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.9699 - val_accuracy: 0.4406\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 3s 535us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.0104 - val_accuracy: 0.4375\n",
      "Epoch 29/30\n",
      "6400/6400 [==============================] - 3s 528us/step - loss: 9.6990e-04 - accuracy: 1.0000 - val_loss: 3.0504 - val_accuracy: 0.4375\n",
      "Epoch 30/30\n",
      "6400/6400 [==============================] - 4s 549us/step - loss: 8.6823e-04 - accuracy: 1.0000 - val_loss: 3.0901 - val_accuracy: 0.4356\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 4 array(s), but instead got the following list of 2 arrays: [array([[   0,    0,    0, ...,  411,    9, 4650],\n       [   0,    0,    0, ...,    4,  694,  368],\n       [   0,    0,    0, ...,   12,  149,  190],\n       ...,\n       [   0,    0,    0, ...,   13, ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-e057383bd31b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m#accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_conv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/thanet/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1350\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/thanet/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/thanet/.local/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 4 array(s), but instead got the following list of 2 arrays: [array([[   0,    0,    0, ...,  411,    9, 4650],\n       [   0,    0,    0, ...,    4,  694,  368],\n       [   0,    0,    0, ...,   12,  149,  190],\n       ...,\n       [   0,    0,    0, ...,   13, ..."
     ]
    }
   ],
   "source": [
    "def create_conv_model(X_train, y_train):\n",
    "    X_train_0,X_train_1,X_train_2,X_train_3 = X_train\n",
    "    model_conv = Sequential()\n",
    "    embedding_vecor_length = X_train_0.shape[1]\n",
    "   # model0 = Sequential()\n",
    "    batch_size=45\n",
    "    #model0\n",
    "    input0 = Input(shape=(X_train_0.shape[1],))\n",
    "    x0 = Embedding(len(vocab_to_int_FalseSent)+1, embedding_vecor_length, input_length=X_train_0.shape[1])(input0)\n",
    "    x0 = (Conv1D(25, 3, activation='relu',name='conv_0'))(x0)\n",
    "    #x0 = MaxPooling1D(pool_size=3)(x0)\n",
    "    \n",
    "    #model1\n",
    "    input1 = Input(shape=(X_train_1.shape[1],))\n",
    "    x1 = Embedding(len(vocab_to_int_OptA)+1, embedding_vecor_length, input_length=X_train_1.shape[1])(input1)\n",
    "    x1 = (Conv1D(25, 3, activation='relu',name='conv_1'))(x1)\n",
    "    #x1 = MaxPooling1D(pool_size=3)(x1)\n",
    "    \n",
    "    #model2\n",
    "    input2 = Input(shape=(X_train_2.shape[1],))\n",
    "    x2 = Embedding(len(vocab_to_int_OptB)+1, embedding_vecor_length, input_length=X_train_1.shape[1])(input2)\n",
    "    x2 = (Conv1D(25, 3, activation='relu',name='conv_2'))(x2)\n",
    "    #x1 = MaxPooling1D(pool_size=3)(x1)\n",
    "    \n",
    "    #model3\n",
    "    input3 = Input(shape=(X_train_3.shape[1],))\n",
    "    x3 = Embedding(len(vocab_to_int_OptC)+1, embedding_vecor_length, input_length=X_train_1.shape[1])(input3)\n",
    "    x3 = (Conv1D(25, 3, activation='relu',name='conv_3'))(x3)\n",
    "    #x1 = MaxPooling1D(pool_size=3)(x1)\n",
    "    \n",
    "    x = Concatenate()([x0,x1,x2,x3])\n",
    "    x = Conv1D(25, 3, activation='relu',name='conv')(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = LSTM(10)(x)\n",
    "    x = Dense(3, activation='sigmoid')(x)\n",
    "    \n",
    "    model_conv = Model(input = [input0,input1,input2,input3], output = x)\n",
    "    model_conv.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    model_conv.summary()\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor='loss', mode='min', min_delta=0,patience=1)\n",
    "    mc = callbacks.ModelCheckpoint('task4A_CNN_model.h5')\n",
    "    \n",
    "    model_conv.fit([X_train_0,X_train_1,X_train_2,X_train_3], y_train, epochs=30,shuffle=False, callbacks=[mc, es],validation_split=0.2)\n",
    "    return model_conv\n",
    "\n",
    "model_conv = create_conv_model([X_train_0,X_train_1,X_train_2,X_train_3], y_train)\n",
    "\n",
    "# Final evaluation of the model\n",
    "predictions = model_conv.predict([X_test_0,X_test_1,X_test_2,X_test_3])\n",
    "inverted = [np.argmax(i) for i in predictions]\n",
    "truth= [np.argmax(i) for i in y_test]\n",
    "#accuracy\n",
    "scores = model_conv.evaluate([X_test_0,X_test_1], y_test, verbose=1)\n",
    "print(scores)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(classification_report(truth,inverted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submission_form(truth, inverted, \"CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 taskB_scorer.py --gold-labels CNNgold_labels.csv --pred-labels CNNpred_labels.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capsule Networks for multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/XifengGuo/CapsNet-Keras.git capsnet-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "cp_meta = ModelCheckpoint(filepath=\"CNN_capsnet_model_Semval_Task4A.h5\",save_best_only=True,verbose=1)\n",
    "tb = TensorBoard(log_dir='./logs',\n",
    "                histogram_freq=0,\n",
    "                write_graph=True,\n",
    "                write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Concatenate,Dropout,Reshape\n",
    "from capsulelayers import CapsuleLayer, PrimaryCap, Length, Mask\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "def CapsNet_Meta(X_train, input_shape, n_class, routings):\n",
    "    \"\"\"\n",
    "    A Capsule Network on text data.\n",
    "    :param input_shape: data shape, 3d, [width, height, channels]\n",
    "    :param n_class: number of classes\n",
    "    :param routings: number of routing iterations\n",
    "    :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n",
    "    `eval_model` can also be used for training.\n",
    "    \"\"\"\n",
    "    X_train_0, X_train_1, X_train_2, X_train_3 = X_train\n",
    "    model_capsnet = Sequential()\n",
    "    embedding_vecor_length = X_train_0.shape[1]\n",
    "    batch_size=45\n",
    "    \n",
    "    #model0\n",
    "    input0 = Input(shape=(X_train_0.shape[1],))\n",
    "    x0 = Embedding(len(vocab_to_int_FalseSent)+1, embedding_vecor_length, input_length=X_train_0.shape[1])(input0)\n",
    "    x0 = (Conv1D(25, 3, activation='relu',name='conv_0'))(x0)\n",
    "    #x0 = MaxPooling1D(pool_size=3)(x0)\n",
    "    \n",
    "    #model1\n",
    "    input1 = Input(shape=(X_train_1.shape[1],))\n",
    "    x1 = Embedding(len(vocab_to_int_OptA)+1, embedding_vecor_length, input_length=X_train_1.shape[1])(input1)\n",
    "    x1 = (Conv1D(25, 3, activation='relu',name='conv_1'))(x1)\n",
    "    \n",
    "    #model2\n",
    "    input2 = Input(shape=(X_train_2.shape[1],))\n",
    "    x2 = Embedding(len(vocab_to_int_OptB)+1, embedding_vecor_length, input_length=X_train_2.shape[1])(input2)\n",
    "    x2 = (Conv1D(25, 3, activation='relu',name='conv_1'))(x2)\n",
    "    \n",
    "    #model1\n",
    "    input3 = Input(shape=(X_train_3.shape[1],))\n",
    "    x3 = Embedding(len(vocab_to_int_OptC)+1, embedding_vecor_length, input_length=X_train_1.shape[1])(input3)\n",
    "    x3 = (Conv1D(25, 3, activation='relu',name='conv_1'))(x3)\n",
    "    \n",
    "    x = Concatenate()([x0,x1,x2,x3])\n",
    "    print(x.shape)\n",
    "    x = Reshape((6,7,25),)(x)\n",
    "    conv2 = layers.Conv2D(filters=25, kernel_size=3, strides=1, padding='valid', activation='relu', name='conv2')(x)\n",
    "    print(conv2.shape)\n",
    "\n",
    "    \n",
    "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "    primarycaps = PrimaryCap(conv2, dim_capsule=4, n_channels=32, kernel_size=3, strides=1, padding='valid')\n",
    "\n",
    "    print(primarycaps)\n",
    "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
    "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings,\n",
    "    name='digitcaps')(primarycaps)\n",
    "    print(digitcaps.shape)\n",
    "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "    # If using tensorflow, this will not be necessary. :)\n",
    "    \n",
    "    #print(out_caps.shape)\n",
    "    \n",
    "    #print(con_M.shape)\n",
    "    out_caps = Length(name='capsnet')(digitcaps)\n",
    "    # Decoder network.\n",
    "    y = layers.Input(shape=(n_class,))\n",
    "    masked_by_y = Mask()([digitcaps, y]) # The true label is used to mask the output of capsule layer. For training\n",
    "    masked = Mask()(digitcaps) # Mask using the capsule with maximal length. For prediction\n",
    "\n",
    "    # Shared Decoder model in training and prediction\n",
    "    decoder = models.Sequential(name='decoder')\n",
    "    decoder.add(layers.Dense(10, activation='relu', input_dim=16*n_class))\n",
    "    decoder.add(layers.Dense(20, activation='relu'))\n",
    "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "    # Models for training and evaluation (prediction)\n",
    "    train_model = models.Model(inputs=[input0, input1, input2, input3], outputs=out_caps)\n",
    "   # eval_model = models.Model([x,meta_d], out_caps)\n",
    "\n",
    "    # manipulate model\n",
    "   # noise = layers.Input(shape=(n_class, 16))\n",
    "   # noised_digitcaps = layers.Add()([digitcaps, noise])\n",
    "   # masked_noised_y = Mask()([noised_digitcaps, y])\n",
    "   # manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
    "    return train_model  #, eval_model  #, manipulate_model\n",
    "\n",
    "model_capsnet = CapsNet_Meta([X_train_0, X_train_1, X_train_2, X_train_3],input_shape=X_train_0.shape[1:], n_class=3, routings=3)\n",
    "\n",
    "model_capsnet.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])  #loss_weights=[1.],\n",
    "model_capsnet.summary()\n",
    "\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto', baseline=None, restore_best_weights=False)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.0001, cooldown=1, min_lr=0.00001)\n",
    "\n",
    "for i in range(1):\n",
    "    history=model_capsnet.fit([X_train_0, X_train_1, X_train_2, X_train_3], y_train, batch_size=45, epochs=15,\n",
    "              validation_split=0.1, callbacks=[cp_meta]).history\n",
    "    model_capsnet.evaluate([X_test_0, X_test_1, X_test_2, X_test_3], y_test)\n",
    "    predictions = model_capsnet.predict([X_test_0, X_test_1, X_test_2, X_test_3])\n",
    "    print(predictions)\n",
    "plt.plot(history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
